{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Framing\n",
    "\n",
    "In the [main notebook](../robust-genetics.ipynb) it's mentioned that the mathematics is more complicated when the robust optimization problem is framed as a risk minimization problem, rather than return maximization as done there. This notebook includes the calculations of the alternative framing to illustrate that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # defines matrix structures\n",
    "from qpsolvers import solve_qp      # used for quadratic optimization\n",
    "import gurobipy as gp               # Gurobi optimization interface (1)\n",
    "from gurobipy import GRB            # Gurobi optimization interface (2)\n",
    "\n",
    "# want to round rather than truncate when printing\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# only show numpy output to five decimal places\n",
    "np.set_printoptions(formatter={'float_kind':\"{:.5f}\".format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Problem\n",
    "\n",
    "In the context of genetic selection, we want to maximize selection of genetic merit (a measure of desirable traits) while minimizing risks due to inbreeding. This can be formed mathematically as a problem about minimizing risk for varying levels of return. We say\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu\\right)\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "where $w$ is the vector of proportional contributions, $\\Sigma$ is a matrix encoding risk, $\\mu$ is a vector encoding returns, $l$ encodes lower bounds on contributions, $u$ encodes upper bounds on contributions, and $M$ is matrix which encodes whether each candidate is a sire or dam as described previously.\n",
    "\n",
    "In this representation of the problem, $\\lambda$ is a control variable which balances how we trade of between risk and return. Each value of $\\lambda$ will give a different solution on the critical frontier of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example ($n = 3$)\n",
    "\n",
    "Lets see how this works in an example. We will start by looking how this problem might be solving using Python's [qpsolvers](https://qpsolvers.github.io/qpsolvers/index.html) library. Consider the problem where\n",
    "$$\n",
    "    \\mu = \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix},\\quad\n",
    "    \\Sigma = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 5 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}, \\quad\n",
    "    \\mathcal{S} = \\lbrace 1 \\rbrace, \\quad\n",
    "    \\mathcal{D} = \\lbrace 2, 3 \\rbrace, \\quad\n",
    "    l = {\\bf 0}, \\quad\n",
    "    u = {\\bf 1}.\n",
    "$$\n",
    "We define these variables in Python using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY PROBLEM VARIABLES\n",
    "problem_size = 3\n",
    "expected_breeding_values = np.array([\n",
    "    1.0,\n",
    "    5.0,\n",
    "    2.0\n",
    "])\n",
    "relationship_matrix = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 5, 0],\n",
    "    [0, 0, 3]\n",
    "])\n",
    "sire_indices = [0]\n",
    "dam_indices  = [1,2]\n",
    "lower_bound = np.full((problem_size, 1), 0.0)\n",
    "upper_bound = np.full((problem_size, 1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the additional variables which need setting up so that the problem works in `qpsolvers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZATION SETUP VARIABLES\n",
    "lam = 0.5\n",
    "# define the M so that column i is [1;0] if i is a sire and [0;1] otherwise \n",
    "M = np.zeros((2, problem_size))\n",
    "M[0, sire_indices] = 1\n",
    "M[1, dam_indices] = 1\n",
    "# define the right hand side of the constraint Mx = m\n",
    "m = np.array([[0.5], [0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we solve the problem using the modules' `solve_qp` function. This utilises Gurobi via an API, a fact which will be important once we start to consider larger problem sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-02-26\n",
      "QP solution: w = [0.50000 0.37500 0.12500]\n"
     ]
    }
   ],
   "source": [
    "# SOLVE THE PROBLEM\n",
    "def solveGS(lam):\n",
    "    return solve_qp(\n",
    "        P = relationship_matrix,\n",
    "        q = -lam*expected_breeding_values,\n",
    "        G = None,\n",
    "        h = None,\n",
    "        A = M,\n",
    "        b = m,\n",
    "        lb = lower_bound,\n",
    "        ub = upper_bound,\n",
    "        solver = \"gurobi\"\n",
    "    )\n",
    "\n",
    "print(f\"QP solution: w = {solveGS(lam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, we have code which is telling us that our optimal contributions for $\\lambda = 0.5$ are $w_1 = 0.5$, $w_2 = 0.375$, and $w_3 = 0.125$. We could vary our $\\lambda$ value too and find other points on the frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0: w = [0.50000 0.18750 0.31250]\n",
      "lambda = 0.2: w = [0.50000 0.26250 0.23750]\n",
      "lambda = 0.4: w = [0.50000 0.33750 0.16250]\n",
      "lambda = 0.6: w = [0.50000 0.41250 0.08750]\n",
      "lambda = 0.8: w = [0.50000 0.48750 0.01250]\n",
      "lambda = 1.0: w = [0.50000 0.50000 0.00000]\n"
     ]
    }
   ],
   "source": [
    "print(f\"lambda = 0.0: w = {solveGS(0.0)}\")\n",
    "print(f\"lambda = 0.2: w = {solveGS(0.2)}\")\n",
    "print(f\"lambda = 0.4: w = {solveGS(0.4)}\")\n",
    "print(f\"lambda = 0.6: w = {solveGS(0.6)}\")\n",
    "print(f\"lambda = 0.8: w = {solveGS(0.8)}\")\n",
    "print(f\"lambda = 1.0: w = {solveGS(1.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Optimization\n",
    "\n",
    "As discussed, rather than treating $\\mu$ as known we must model it using a univariate normal distribution, $\\mu\\sim N(\\bar{\\mu}, \\Omega)$. We adjust the objective function to model the inherent uncertainty in the problem, and in the risk-minimization framing the problem the bilevel optimization problem is\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda\\max_{\\mu\\in U_{\\mu}} \\left(w^{T}\\mu \\right)\\right)\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Uncertainty Sets\n",
    "\n",
    "We define $U_\\mu$ as a quadratic uncertainty set,\n",
    "$$\n",
    "    U_{\\mu} := \\left\\lbrace \\mu :\\ {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\leq \\kappa^2 \\right\\rbrace.\n",
    "$$\n",
    "This means that our lower level problem $\\max_{\\mu\\in U_{\\mu}} w^{T}\\mu$ becomes\n",
    "$$\n",
    "    \\max_{\\mu} w^{T}\\mu\\quad \\text{subject to}\\quad {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\leq \\kappa^2,\n",
    "$$\n",
    "or, in standard form,\n",
    "$$\n",
    "    \\min_{\\mu} \\left(-w^{T}\\mu\\right) \\quad\\text{subject to}\\quad \\kappa^2 - {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\geq 0.\n",
    "$$\n",
    "This is convex, since $\\Omega$ is a positive definite matrix and $-w^{T}\\mu$ is an affine function. If we define a Lagrangian multiplier $\\rho\\in\\mathbb{R}$, the KKT conditions of this problem are:\n",
    "\\begin{align}\n",
    "    \\nabla_{\\mu}L(\\mu, \\rho) = 0 \\quad&\\Rightarrow\\quad \\nabla_{\\mu}\\left( -w^{T}\\mu - \\rho\\big( \\kappa^2 - {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\big) \\right) = 0, \\\\\n",
    "    c(\\mu) \\geq 0                \\quad&\\Rightarrow\\quad \\kappa^2 - {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\geq 0, \\\\\n",
    "    \\rho \\geq 0                  \\quad&\\Rightarrow\\quad \\rho\\geq0, \\\\\n",
    "    \\rho c(\\mu) = 0              \\quad&\\Rightarrow\\quad \\rho\\left(\\kappa^2 - {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\right) = 0.\n",
    "\\end{align}\n",
    "From (1) we have that\n",
    "$$\n",
    "    -w + \\rho 2\\Omega^{-1}(\\mu-\\bar{\\mu}) = 0 \\quad\\Rightarrow\\quad \\mu - \\bar{\\mu} = \\frac{1}{2\\rho}\\Omega w \\qquad (5)\n",
    "$$\n",
    "which when substituted into (4) gives\n",
    "\\begin{align*}\n",
    "    &\\phantom{\\Rightarrow}\\quad \\rho\\left( \\kappa^2 - {(\\mu-\\bar{\\mu})}^{T}\\Omega^{-1}(\\mu-\\bar{\\mu}) \\right) = 0 \\\\\n",
    "    &\\Rightarrow\\quad \\rho\\left( \\kappa^2 - \\big(\\frac{1}{2\\rho}\\Omega w\\big)^{T}\\Omega^{-1}\\big(\\frac{1}{2\\rho}\\Omega w\\big) \\right) = 0 \\\\\n",
    "    &\\Rightarrow\\quad \\rho\\kappa^2 - \\frac{1}{4\\rho}w^{T}\\Omega^{T}\\Omega^{-1}\\Omega w = 0 \\\\\n",
    "    &\\Rightarrow\\quad \\rho^2\\kappa^2 = \\frac{1}{4}w^{T}\\Omega w\\quad \\text{(since $\\Omega$ symmetric)} \\\\\n",
    "    &\\Rightarrow\\quad \\rho\\kappa = \\frac{1}{2}\\sqrt{w^{T}\\Omega w}\\quad \\text{(since $\\rho,\\kappa\\geq0$)} \\\\\n",
    "    &\\Rightarrow\\quad \\frac{1}{2\\rho} = \\frac{\\kappa}{\\sqrt{w^{T}\\Omega w}}.\n",
    "\\end{align*}\n",
    "Substituting this back into (5), we find that\n",
    "$$\n",
    "    \\mu - \\bar{\\mu} = \\frac{\\kappa}{\\sqrt{w^{T}\\Omega w}}\\Omega w \\quad\\Rightarrow\\quad \\mu = \\bar{\\mu} + \\frac{\\kappa}{\\sqrt{w^{T}\\Omega w}}\\Omega w\n",
    "$$\n",
    "as the solution for the inner problem. Substituting this back into the outer problem gives\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\left( \\bar{\\mu} + \\frac{\\kappa}{\\sqrt{w^{T}\\Omega w}}\\Omega w \\right)\\right)\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$\n",
    "which after simplifying down and rationalizing the denominator becomes\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\bar{\\mu} - \\lambda\\kappa\\sqrt{w^{T}\\Omega w}\\right)\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u\n",
    "$$\n",
    "where $\\kappa\\in\\mathbb{R}$ is our robust optimization parameter. Since our objective has gained an additional square root term, this is obviously no longer a quadratic problem and `qpsolvers` is no longer a viable tool. We will instead now need to work with the Gurobi API directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gurobi\n",
    "\n",
    "To illustrate how the setup changes when uncertainty is added, we will first look at how Gurobi handles the standard problem. The following code returns the same solution as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 22 rows, 3 columns and 24 nonzeros\n",
      "Model fingerprint: 0xd96d3c43\n",
      "Model has 3 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 21 rows and 1 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1 rows, 2 columns, 2 nonzeros\n",
      "Presolved model has 2 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 0.000e+00\n",
      " Factor NZ  : 1.000e+00\n",
      " Factor Ops : 1.000e+00 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   5.30849490e+05 -5.31975390e+05  1.50e+03 0.00e+00  3.13e+05     0s\n",
      "   1   7.57990696e+02 -1.61071935e+03  3.58e+01 1.71e-13  7.91e+03     0s\n",
      "   2  -7.64387653e-01 -8.13186089e+02  3.58e-05 1.23e-14  2.03e+02     0s\n",
      "   3  -7.64406933e-01 -2.00154147e+00  1.88e-08 6.43e-14  3.09e-01     0s\n",
      "   4  -7.99897456e-01 -9.97000994e-01  1.46e-09 4.86e-15  4.93e-02     0s\n",
      "   5  -8.12408202e-01 -8.31800574e-01  1.33e-15 2.78e-17  4.85e-03     0s\n",
      "   6  -8.12499997e-01 -8.12540276e-01  0.00e+00 0.00e+00  1.01e-05     0s\n",
      "   7  -8.12500000e-01 -8.12500040e-01  0.00e+00 2.78e-17  1.01e-08     0s\n",
      "   8  -8.12500000e-01 -8.12500000e-01  2.22e-16 5.55e-17  1.01e-11     0s\n",
      "\n",
      "Barrier solved model in 8 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective -8.12500000e-01\n",
      "\n",
      "w = [0.50000 0.37500 0.12500]\n"
     ]
    }
   ],
   "source": [
    "# create a model for standard genetic selection\n",
    "model = gp.Model(\"standardGS\")\n",
    "\n",
    "# define variable of interest as a continuous \n",
    "w = model.addMVar(shape=problem_size, lb=0.0, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "\n",
    "# set the objective function\n",
    "model.setObjective(\n",
    "    0.5*w.transpose()@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "# add sub-to-half constraints\n",
    "model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "# add weight-bound constraints\n",
    "model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "# solve the problem with Gurobi\n",
    "model.optimize()\n",
    "print(f\"w = {w.X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately Gurobi cannot handle our problem with its objective function in the form\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\lambda\\kappa\\sqrt{w^{T}\\Omega w}\\right)\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "so further adjustments are needed first. If we define a real auxillary variable $z\\geq0$ such that $z\\leq\\sqrt{w^{T}\\Omega w}$, then our problem becomes\n",
    "$$\n",
    "    \\min_w \\left(\\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\lambda\\kappa z\\right)\\ \\text{ s.t. }\\ z\\leq\\sqrt{w^{T}\\Omega w},\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$\n",
    "Since $\\kappa,\\lambda\\geq0$, and we're minimizing an objective containing \"$-\\lambda\\kappa z$\", this term of the objective will be smallest when $z>0$ is biggest. This happens precisely when it attains its upper bound from the constraint $z\\leq\\sqrt{w^{T}\\Omega w}$, hence our relaxation is justified since $z$ will push upwards.\n",
    "\n",
    "However, Gurobi _still_ can't handle this due to the presence of the square root, so we further make use of both $z$ and $\\sqrt{w^{T}\\Omega w}$ being positive to note that $z\\leq\\sqrt{w^{T}\\Omega w}$ can be squared on both sides:\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\lambda\\kappa z\\ \\text{ s.t. }\\ z^2\\leq w^{T}\\Omega w,\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore this with our toy problem from before, we will define\n",
    "$$\n",
    "    \\bar{\\mu} = \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix},\\quad\n",
    "    \\Omega = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & \\frac{1}{8} \\end{bmatrix},\\quad\n",
    "    \\kappa = 0.5\n",
    "$$\n",
    "and retain the other variables as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 4, 0],\n",
    "    [0, 0, 1/8]\n",
    "])\n",
    "\n",
    "kappa = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then formulate this in Python as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 22 rows, 4 columns and 24 nonzeros\n",
      "Model fingerprint: 0xf7819a35\n",
      "Model has 3 quadratic objective terms\n",
      "Model has 1 quadratic constraint\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  QMatrix range    [1e-01, 4e+00]\n",
      "  Objective range  [2e-01, 2e+00]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 21 rows and 1 columns\n",
      "\n",
      "Continuous model is non-convex -- solving as a MIP\n",
      "\n",
      "Presolve removed 21 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 4 rows, 6 columns, 9 nonzeros\n",
      "Presolved model has 2 quadratic objective terms\n",
      "Presolved model has 1 quadratic constraint(s)\n",
      "Presolved model has 2 bilinear constraint(s)\n",
      "Variable types: 6 continuous, 0 integer (0 binary)\n",
      "Found heuristic solution: objective -1.0491801\n",
      "\n",
      "Root relaxation: objective -1.095481e+00, 4 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   -1.09548    0    -   -1.04918   -1.09548  4.41%     -    0s\n",
      "     0     0   -1.09548    0    1   -1.04918   -1.09548  4.41%     -    0s\n",
      "     0     0   -1.08932    0    2   -1.04918   -1.08932  3.83%     -    0s\n",
      "     0     0   -1.08772    0    2   -1.04918   -1.08772  3.67%     -    0s\n",
      "     0     0   -1.08664    0    2   -1.04918   -1.08664  3.57%     -    0s\n",
      "     0     0   -1.08587    0    2   -1.04918   -1.08587  3.50%     -    0s\n",
      "     0     0   -1.08527    0    1   -1.04918   -1.08527  3.44%     -    0s\n",
      "     0     0   -1.08481    0    1   -1.04918   -1.08481  3.40%     -    0s\n",
      "     0     0   -1.08443    0    1   -1.04918   -1.08443  3.36%     -    0s\n",
      "     0     0   -1.08415    0    2   -1.04918   -1.08415  3.33%     -    0s\n",
      "     0     0   -1.04960    0    2   -1.04918   -1.04960  0.04%     -    0s\n",
      "     0     0   -1.04955    0    2   -1.04918   -1.04955  0.04%     -    0s\n",
      "     0     2   -1.04955    0    2   -1.04918   -1.04955  0.04%     -    0s\n",
      "\n",
      "Explored 3 nodes (22 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: -1.04918 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -1.049180143116e+00, best bound -1.049222787703e+00, gap 0.0041%\n",
      "w = [0.50000 0.42869 0.07131],\n",
      "z = 0.9928459846964108.\n"
     ]
    }
   ],
   "source": [
    "# create a new model for robust genetic selection\n",
    "model = gp.Model(\"robustGS\")\n",
    "\n",
    "# define variables of interest as a continuous\n",
    "w = model.addMVar(shape=problem_size, lb=0.0, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "z = model.addVar(lb=0.0, name=\"z\")\n",
    "\n",
    "# setup the robust objective function\n",
    "model.setObjective(\n",
    "    0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values - lam*kappa*z,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "# add quadratic uncertainty constraint\n",
    "model.addConstr(z**2 <= w.transpose()@omega@w, name=\"uncertainty\")\n",
    "# add sub-to-half constraints\n",
    "model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "# add weight-bound constraints\n",
    "model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "# solve the problem with Gurobi\n",
    "model.optimize()\n",
    "print(f\"w = {w.X},\\nz = {z.X}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this experiment with varying $\\kappa$ to see how how different tolerances for uncertainty impact the robust turning point returned.\n",
    "\n",
    "| $\\kappa$ |        $w$            |   $z$   | $f(w,z)$ | Gap |\n",
    "| ---: | ------------------------: | ------: | -------: | --: |\n",
    "|  0.0 | [0.50000 0.37500 0.12500] | 0.0 | -8.12500000e-01 | 0% |\n",
    "|  0.5 | [0.50000 0.42869 0.07131] | 0.9928459846964108 | -1.049180143116e+00 | 0.0041% |\n",
    "|  1.0 | [0.50000 0.48606 0.01394] | 1.0931753188733573 | -1.309752491846e+00 | 0.0023% |\n",
    "|  2.0 | [0.50000 0.50000 0.00000] | 1.1180339796124110 | -1.868033983797e+00 | 0.0005% |\n",
    "|  4.0 | [0.50000 0.50000 0.00000] | 1.1180339856336740 | -2.986067972548e+00 | 0.0021%\n",
    "\n",
    "We can see that in the case $\\kappa = 0$ we return the standard optimization solution, as expected. We also note that there are not further changes once $\\kappa$ falls above a certain threshold, indicating that we have successfully converged to the \"riskiest\" portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real (Simulated) Data\n",
    "\n",
    "Now we've looked at how these problems can be approached with Gurobi, we can try an example with realistic simulated data. Here we have data for a cohort of 50 candidates split across three data files, each containing space-separated values.\n",
    "\n",
    "1. In `A50.txt` the matrix $\\Sigma$ is described, with columns for $i$, $j$, and $a_{ij}$, where only the upper triangle is described since the matrix is symmetric.\n",
    "2. In `EBV50.txt` the vector $\\bar{\\mu}$ is described, with only one column containing the posterior mean over 1000 samples.\n",
    "3. In `S50.txt` the matrix $\\Omega$ is described, with columns for $i$, $j$, and $\\sigma_{ij}$, where only the upper triangle is described since the matrix is symmetric.\n",
    "\n",
    "Note that this particular problem does not contain a separate file for sex data; odd indexed candidates are sires and even indexed candidates are dams. For now, we also don't have a $l$ or $u$ bounding the possible weights.\n",
    "\n",
    "\n",
    "The first step then is clearly going to be loading the matrices in particular from file. We create the following function to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_problem(A_filename, E_filename, S_filename, dimension=False):\n",
    "    \"\"\"\n",
    "    Used to load genetic selection problems into NumPy. It takes three\n",
    "    string inputs for filenames where Sigma, Mu, and Omega are stored,\n",
    "    as well as an optional integer input for problem dimension if this\n",
    "    is known. If it's know know, it's worked out based on E_filename.\n",
    "\n",
    "    As output, it returns (A, E, S, n), where A and S are n-by-n NumPy\n",
    "    arrays, E is a length n NumPy array, and n is an integer.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_symmetric_matrix(filename, dimension):\n",
    "        \"\"\"\n",
    "        Since NumPy doesn't have a stock way to load matrices\n",
    "        stored in coordinate format format, this adds one.\n",
    "        \"\"\"\n",
    "\n",
    "        matrix = np.zeros([dimension, dimension])\n",
    "\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                i, j, entry = line.split(\" \")\n",
    "                # data files indexed from 1, not 0\n",
    "                matrix[int(i)-1, int(j)-1] = entry\n",
    "                matrix[int(j)-1, int(i)-1] = entry\n",
    "\n",
    "        return matrix\n",
    "\n",
    "\n",
    "    # if dimension wasn't supplied, need to find that\n",
    "    if not dimension:\n",
    "        # get dimension from EBV, since it's the smallest file\n",
    "        with open(E_filename, 'r') as file:\n",
    "            dimension = sum(1 for _ in file)\n",
    "\n",
    "    # EBV isn't in coordinate format so can be loaded directly\n",
    "    E = np.loadtxt(E_filename)  \n",
    "    # A and S are stored by coordinates so need special loader\n",
    "    A = load_symmetric_matrix(A_filename, dimension)\n",
    "    S = load_symmetric_matrix(S_filename, dimension)\n",
    "\n",
    "    return A, E, S, dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given example problem we can now solve it with Gurobi using the exact same methods as before, for both the standard genetic selection problem and the robust version of the problem. The following cell does both alongside each other to accentuate the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 300\n",
      "Set parameter MIPGap to value 0.05\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4 rows, 50 columns and 100 nonzeros\n",
      "Model fingerprint: 0x534ff85e\n",
      "Model has 1275 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e-01, 1e+00]\n",
      "  QObjective range [5e-02, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 5e-01]\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 2 rows, 50 columns, 50 nonzeros\n",
      "Presolved model has 1275 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " Free vars  : 49\n",
      " AA' NZ     : 1.274e+03\n",
      " Factor NZ  : 1.326e+03\n",
      " Factor Ops : 4.553e+04 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.76397773e+05 -4.22619805e+05  2.50e+04 1.12e+00  9.99e+05     0s\n",
      "   1  -5.01117677e+01 -9.99230833e+02  2.68e+01 1.25e-04  1.09e+03     0s\n",
      "   2  -8.81632395e-01 -9.63667643e+02  2.68e-05 1.25e-10  1.93e+01     0s\n",
      "   3  -8.81606636e-01 -2.03034027e+00  5.19e-09 2.41e-14  2.30e-02     0s\n",
      "   4  -9.04332054e-01 -1.04180295e+00  4.73e-10 2.19e-15  2.75e-03     0s\n",
      "   5  -9.59656693e-01 -1.01318293e+00  1.67e-15 8.88e-16  1.07e-03     0s\n",
      "   6  -9.73793052e-01 -9.76849441e-01  2.22e-16 1.33e-15  6.11e-05     0s\n",
      "   7  -9.76163966e-01 -9.76239391e-01  1.39e-15 6.66e-16  1.51e-06     0s\n",
      "   8  -9.76213879e-01 -9.76217890e-01  9.91e-15 5.55e-16  8.02e-08     0s\n",
      "   9  -9.76215229e-01 -9.76215592e-01  1.65e-13 5.55e-16  7.25e-09     0s\n",
      "  10  -9.76215438e-01 -9.76215482e-01  7.03e-13 6.66e-16  8.86e-10     0s\n",
      "  11  -9.76215473e-01 -9.76215476e-01  4.24e-13 6.66e-16  4.91e-11     0s\n",
      "\n",
      "Barrier solved model in 11 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective -9.76215473e-01\n",
      "\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4 rows, 51 columns and 100 nonzeros\n",
      "Model fingerprint: 0xd47c065e\n",
      "Model has 1275 quadratic objective terms\n",
      "Model has 1 quadratic constraint\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  QMatrix range    [1e-05, 1e+00]\n",
      "  Objective range  [7e-01, 1e+00]\n",
      "  QObjective range [5e-02, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 5e-01]\n",
      "Presolve removed 2 rows and 0 columns\n",
      "\n",
      "Continuous model is non-convex -- solving as a MIP\n",
      "\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2503 rows, 1327 columns, 6326 nonzeros\n",
      "Presolved model has 1275 quadratic objective terms\n",
      "Presolved model has 1 quadratic constraint(s)\n",
      "Presolved model has 1275 bilinear constraint(s)\n",
      "Variable types: 1327 continuous, 0 integer (0 binary)\n",
      "Found heuristic solution: objective -1.1617295\n",
      "\n",
      "Root relaxation: objective -3.490954e+00, 43 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   -3.49095    0   38   -1.16173   -3.49095   200%     -    0s\n",
      "     0     0   -3.49095    0   42   -1.16173   -3.49095   200%     -    0s\n",
      "     0     0   -1.58157    0  231   -1.16173   -1.58157  36.1%     -    0s\n",
      "     0     0   -1.34540    0  512   -1.16173   -1.34540  15.8%     -    0s\n",
      "     0     0   -1.32278    0  619   -1.16173   -1.32278  13.9%     -    0s\n",
      "     0     0   -1.32278    0   59   -1.16173   -1.32278  13.9%     -    1s\n",
      "     0     0   -1.32278    0   59   -1.16173   -1.32278  13.9%     -    1s\n",
      "     0     2   -1.32278    0   59   -1.16173   -1.32278  13.9%     -    1s\n",
      "   110   118   -1.23808   14  191   -1.16173   -1.27940  10.1%   343    5s\n",
      "   340   353   -1.19438   40  319   -1.16173   -1.27940  10.1%   377   10s\n",
      "H  551   573                      -1.1617295   -1.27240  9.53%   438   12s\n",
      "\n",
      "Explored 600 nodes (256270 simplex iterations) in 13.46 seconds (12.04 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: -1.16173 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective -1.161729466120e+00, best bound -1.217554010902e+00, gap 4.8053%\n",
      "\n",
      "SIRE WEIGHTS\t\t\t DAM WEIGHTS\n",
      "--------------------\t\t --------------------\n",
      " i   w_std    w_rbs\t\t  i   w_std    w_rbs\n",
      "00  0.00000  0.00000             01  0.08319  0.14976\n",
      "02  0.11649  0.49337             03  0.00000  0.00000\n",
      "04  0.00000  0.00000             05  0.00000  0.00000\n",
      "06  0.00000  0.00000             07  0.06817  0.06251\n",
      "08  0.00000  0.00000             09  0.03762  0.00000\n",
      "10  0.00000  0.00000             11  0.00000  0.00000\n",
      "12  0.00000  0.00000             13  0.00355  0.00000\n",
      "14  0.11542  0.00518             15  0.06966  0.00000\n",
      "16  0.00000  0.00000             17  0.00000  0.00000\n",
      "18  0.00000  0.00000             19  0.00000  0.00000\n",
      "20  0.00000  0.00000             21  0.00001  0.00000\n",
      "22  0.00000  0.00000             23  0.00000  0.00000\n",
      "24  0.03537  0.00000             25  0.00000  0.00000\n",
      "26  0.00000  0.00000             27  0.00000  0.00000\n",
      "28  0.00000  0.00000             29  0.00000  0.00000\n",
      "30  0.00000  0.00000             31  0.03580  0.00000\n",
      "32  0.08447  0.00000             33  0.00000  0.00000\n",
      "34  0.00000  0.00000             35  0.02849  0.09487\n",
      "36  0.13489  0.00144             37  0.07446  0.10716\n",
      "38  0.00000  0.00000             39  0.00000  0.00000\n",
      "40  0.00000  0.00000             41  0.07312  0.08570\n",
      "42  0.00000  0.00000             43  0.00000  0.00000\n",
      "44  0.01336  0.00000             45  0.00000  0.00000\n",
      "46  0.00000  0.00000             47  0.02593  0.00000\n",
      "48  0.00000  0.00000             49  0.00000  0.00000\n",
      "\n",
      "Maximum change: 0.37689\n",
      "Average change: 0.02220\n",
      "Minimum change: 0.00000\n"
     ]
    }
   ],
   "source": [
    "sigma, mubar, omega, n = load_problem(\n",
    "    \"../Example/A50.txt\",\n",
    "    \"../Example/EBV50.txt\",\n",
    "    \"../Example/S50.txt\",\n",
    "    50)\n",
    "\n",
    "lam = 0.5\n",
    "kappa = 2\n",
    "\n",
    "# define the M so that column i is [1;0] if i is a sire (so even) and [0;1] otherwise \n",
    "M = np.zeros((2, n))\n",
    "M[0, range(0,50,2)] = 1\n",
    "M[1, range(1,50,2)] = 1\n",
    "# define the right hand side of the constraint Mx = m\n",
    "m = np.array([[0.5], [0.5]])\n",
    "\n",
    "# create models for standard and robust genetic selection\n",
    "model_std = gp.Model(\"n50standard\")\n",
    "model_rbs = gp.Model(\"n50robust\")\n",
    "\n",
    "# initialise w for both models, z for robust model\n",
    "w_std = model_std.addMVar(shape=n, lb=0.0, vtype=GRB.CONTINUOUS, name=\"w\") \n",
    "w_rbs = model_rbs.addMVar(shape=n, lb=0.0, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "z_rbs = model_rbs.addVar(lb=0.0, name=\"z\")\n",
    "\n",
    "# define the objective functions for both models\n",
    "model_std.setObjective(\n",
    "    0.5*w_std.transpose()@(sigma@w_std) - lam*w_std.transpose()@mubar,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "model_rbs.setObjective(\n",
    "    # Gurobi does offer a way to set one objective in terms of another, i.e.\n",
    "    # we could use `model_std.getObjective() - lam*kappa*z_rbs` to define this\n",
    "    # robust objective, but it results in a significant slowdown in code.\n",
    "    0.5*w_rbs.transpose()@(sigma@w_rbs) - lam*w_rbs.transpose()@mubar - lam*kappa*z_rbs,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "# add sum-to-half constraints to both models\n",
    "model_std.addConstr(M @ w_std == m, name=\"sum-to-half\")\n",
    "model_rbs.addConstr(M @ w_rbs == m, name=\"sum-to-half\")\n",
    "\n",
    "# add quadratic uncertainty constraint to the robust model\n",
    "model_rbs.addConstr(z_rbs**2 <= w_rbs.transpose()@omega@w_rbs, name=\"uncertainty\")\n",
    "\n",
    "# since working with non-trivial size, set a time limit\n",
    "time_limit = 60*5  # 5 minutes\n",
    "model_std.setParam(GRB.Param.TimeLimit, time_limit)\n",
    "model_std.setParam(GRB.Param.TimeLimit, time_limit)\n",
    "\n",
    "# for the same reason, also set a duality gap tolerance\n",
    "duality_gap = 0.05\n",
    "model_std.setParam('MIPGap', duality_gap)\n",
    "model_rbs.setParam('MIPGap', duality_gap)\n",
    "\n",
    "# solve both problems with Gurobi\n",
    "model_std.optimize()\n",
    "model_rbs.optimize()\n",
    "\n",
    "# HACK code which prints the results for comparison in a nice format\n",
    "print(\"\\nSIRE WEIGHTS\\t\\t\\t DAM WEIGHTS\")\n",
    "print(\"-\"*20 + \"\\t\\t \" + \"-\"*20)\n",
    "print(\" i   w_std    w_rbs\\t\\t  i   w_std    w_rbs\")\n",
    "for candidate in range(25):\n",
    "    print(f\"{candidate*2:02d}  {w_std.X[candidate*2]:.5f}  {w_rbs.X[candidate*2]:.5f} \\\n",
    "            {candidate*2+1:02d}  {w_std.X[candidate*2+1]:.5f}  {w_rbs.X[candidate*2+1]:.5f}\")\n",
    "    \n",
    "print(f\"\\nMaximum change: {max(np.abs(w_std.X-w_rbs.X)):.5f}\")\n",
    "print(f\"Average change: {np.mean(np.abs(w_std.X-w_rbs.X)):.5f}\")\n",
    "print(f\"Minimum change: {min(np.abs(w_std.X-w_rbs.X)):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with parameters $\\lambda = 0.5, \\kappa = 2$, there's a more significant shift in the portfolios produced and we see in the return maximization version of the problem. It also takes Gurobi significantly longer to compute. More testing would be needed to confirm why this was the case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
