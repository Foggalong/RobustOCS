{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Optimization for Genetic Selection\n",
    "\n",
    "This is a working notebook, looking at how the quadratic optimization problem (QP) which arises in the context of robust genetic selection can be solved with Python (tested with 3.10 specifically). There are some standard packages which this depends on, imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # defines matrix structures\n",
    "from numpy import linalg as nla     # access Numpy's NLA functions\n",
    "from qpsolvers import solve_qp      # used for quadratic optimization\n",
    "from time import perf_counter       # fine grained timing \n",
    "import gurobipy as gp               # Gurobi optimization interface (1)\n",
    "from gurobipy import GRB            # Gurobi optimization interface (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions and output settings used in this notebook are defined in the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTime(task, tic, toc):\n",
    "    \"\"\"Quick function for nicely printing a time to 5 s.f.\"\"\"\n",
    "    print(f\"{task} in {toc - tic:0.5f} seconds\\n\")\n",
    "\n",
    "\n",
    "def printMatrix(matrix, description=\"ans =\", precision=3):\n",
    "    \"\"\"Quick function for nicely printing a matrix\"\"\"\n",
    "    print(f\"{description}\\n\", np.round(matrix, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to round rather than truncate when printing\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Pedigrees\n",
    "\n",
    "We start by reviewing the basic functions needed for handling genetics input data, describing the relationship structure of a cohort of organisms.\n",
    "\n",
    "These structures, sometimes referred to as pedigrees, are commonly stored in `*.ped` data files. The files are essentially a CSV format with three columns $i$, $p$, and $q$, where $i$ is the index of the organism, and $p$ and $q$ are indices of $i$'s parents. Unknown parents (_i.e._ where the parent of an organism within the cohort is from outside the cohort) are represented by a zero. Note that it doesn't matter whether each of $p$ and $q$ is a sire or dam, but the labelling must be such that $p < q$.\n",
    "\n",
    "We read these files into a dictionary using `readPed` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPed(filename):\n",
    "    \"\"\"\n",
    "    Function for reading *.ped files to a dictionary. Takes the file name\n",
    "    as a string input and returns the pedigree structure as a dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        # first line of *.ped lists the headers; skip\n",
    "        file.readline()\n",
    "        # create a list of int lists from each line (dropping optional labels)\n",
    "        data = [[int(x) for x in line.split(\",\")[0:3]] for line in file]\n",
    "    # convert this list of lists into a dictionary\n",
    "    ped = {entry[0]: entry[1:3] for entry in data}\n",
    "    return(ped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have read the pedigree file we can construct Wright's Numerator Relationship Matrix (WNRM), a matrix $A$ which encodes the relationship between organisms $i$ and $j$ as $A_{ij}$. This defined as\n",
    "$$\n",
    "    A_{(i, j)} = A_{(j, i)} = \\frac{1}{2}\\left( A_{(j,p)} + A_{(j,q)} \\right),~\\forall i = 1, \\ldots, m,~\\forall j=1,\\ldots,i-1\n",
    "$$\n",
    "for the off diagonal entries and\n",
    "$$\n",
    "    A_{(i,i)} = 1 + \\frac{1}{2}A_{(p,q)}\n",
    "$$\n",
    "for the diagonal entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeA(pedigree):\n",
    "    \"\"\"\n",
    "    Construct Wright's Numerator Relationship Matrix from a given pedigree\n",
    "    structure. Takes the pedigree as a dictionary input and returns the\n",
    "    matrix as output.\n",
    "    \"\"\"\n",
    "    m = len(pedigree)\n",
    "    A = np.zeros((m, m))\n",
    "\n",
    "    # iterate over rows\n",
    "    for i in range(0, m):\n",
    "        # save parent indexes: pedigrees indexed from 1, Python from 0\n",
    "        p = pedigree[i+1][0]-1\n",
    "        q = pedigree[i+1][1]-1\n",
    "        # iterate over columns sub-diagonal\n",
    "        for j in range(0, i):\n",
    "            # calculate sub-diagonal entries\n",
    "            A[i, j] = 0.5*(A[j, p] + A[j, q])\n",
    "            # populate sup-diagonal (symmetric)\n",
    "            A[j, i] = A[i, j]\n",
    "        # calculate diagonal entries\n",
    "        A[i, i] = 1 + 0.5*A[p, q]\n",
    "\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our work we also need the inverse of this matrix, $A^{-1}$. While we could compute this explicitly or using a decomposition, it's more efficient to use shortcuts highlighted by Henderson and Quass. Given $A$ is a positive definite matrix, it has a Cholesky factorisation $A = L^{T}L$. We compute this factor using `makeL` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeL(pedigree):\n",
    "    \"\"\"\n",
    "    Construct the Cholesky factor L of Wright's Numerator Relationship Matrix\n",
    "    from a given pedigree structure. Takes the pedigree as a dictionary input\n",
    "    and returns the matrix L (in A = L'L) as output.\n",
    "    \"\"\"\n",
    "    m = len(pedigree)\n",
    "    L = np.zeros((m, m))\n",
    "\n",
    "    # iterate over rows\n",
    "    for i in range(0, m):\n",
    "        # save parent indexes: pedigrees indexed from 1, Python from 0\n",
    "        p = pedigree[i+1][0]-1\n",
    "        q = pedigree[i+1][1]-1\n",
    "\n",
    "        # case where both parents are known; p < q bny *.ped convention\n",
    "        if p >= 0 and q >= 0:\n",
    "            for j in range(0, p+1):\n",
    "                L[i, j] = 0.5*(L[p, j] + L[q, j])\n",
    "            for j in range(p+1, q+1):\n",
    "                L[i, j] = 0.5*L[q, j]\n",
    "            # and L[i,j] = 0 for j = (q+1):i\n",
    "\n",
    "            # compute the diagonal\n",
    "            s = 1\n",
    "            for j in range(0, p+1):\n",
    "                s += 0.5*L[p, j]*L[q, j]\n",
    "            for j in range(0, q+1):\n",
    "                s -= L[i, j]**2\n",
    "            L[i, i] = s**0.5\n",
    "\n",
    "        # case where one parent is known; p by *.ped convention\n",
    "        elif p >= 0:  # and q = 0\n",
    "            for j in range(0, p+1):\n",
    "                L[i, j] = 0.5*L[p, j]\n",
    "            # and L[i,j] = 0 for j = (q+1):i\n",
    "\n",
    "            # compute the diagonal\n",
    "            s = 1\n",
    "            for j in range(0, p+1):\n",
    "                s -= L[i, j]**2\n",
    "            L[i, i] = s**0.5\n",
    "\n",
    "        else:\n",
    "            for j in range(0, i):\n",
    "                L[i, j] = 0\n",
    "            L[i, i] = 1\n",
    "\n",
    "    return(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this $L$, and observing also that $A = L^{T}L = T^{T}DDT$ (where $T$ is a triangular matrix and $D$ a diagonal matrix), we further compute the inverse of $D^2$ using `make_invD2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_invD2(pedigree):\n",
    "    \"\"\"\n",
    "    Construct the inverse of the D^2 factor from the Henderson (1976)\n",
    "    decomposition of a WNRM. Takes the pedigree as a dictionary input\n",
    "    and returns the inverse of matrix D^2 (in A = L'L = T'DDT) as output.\n",
    "    \"\"\"\n",
    "    m = len(pedigree)\n",
    "    L = makeL(pedigree)\n",
    "    invD2 = np.zeros((m, m))  # TODO find a way to store diagonal matrices\n",
    "\n",
    "    # iterate over rows\n",
    "    for i in range(0, m):\n",
    "        invD2[i, i] = 1/(L[i, i]**2)\n",
    "\n",
    "    return(invD2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use $D^{-1}$ and exploit the structure of the pedigree (using shortcuts highlighted by Henderson) to compute $A^{-1}$ directly. The algorithm for this is given in `make_invA` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_invA(pedigree):\n",
    "    \"\"\"\n",
    "    Compute the inverse of A using a shortcut which exploits\n",
    "    of its T and D decomposition, detailed in Henderson (1976).\n",
    "    Takes the pedigree as a dictionary input and returns the\n",
    "    inverse as matrix output.\n",
    "    \"\"\"\n",
    "    m = len(pedigree)\n",
    "    B = make_invD2(pedigree)\n",
    "    invA = B\n",
    "\n",
    "    for i in range(0, m):\n",
    "        # label parents p & q\n",
    "        p = pedigree[i+1][0]-1\n",
    "        q = pedigree[i+1][1]-1\n",
    "\n",
    "        # case where both both parents are known\n",
    "        if p >= 0 and q >= 0:\n",
    "            x = -0.5*B[i, i]\n",
    "            y = 0.25*B[i, i]\n",
    "            invA[p, i] += x\n",
    "            invA[i, p] += x\n",
    "            invA[q, i] += x\n",
    "            invA[i, q] += x\n",
    "            invA[p, p] += y\n",
    "            invA[p, q] += y\n",
    "            invA[q, p] += y\n",
    "            invA[q, q] += y\n",
    "\n",
    "        # case where one parent is known; p by *.ped convention\n",
    "        elif p >= 0:\n",
    "            x = -0.5*B[i, i]\n",
    "            invA[p, i] += x\n",
    "            invA[i, p] += x\n",
    "            invA[p, p] += 0.25*B[i, i]\n",
    "\n",
    "    return(invA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the following pedigree data from Henderson (1976), _A Simple Method for Computing the Inverse of a Numerator Relationship Matrix Used in Prediction of Breeding Values_ in Biometrics 32:1, pg. 69-83 (Table 1).\n",
    "\n",
    "|$i$|$p$|$q$|\n",
    "|:-:|:-:|:-:|\n",
    "| i | p | q |\n",
    "| 1 | 0 | 0 |\n",
    "| 2 | 0 | 0 |\n",
    "| 3 | 1 | 0 |\n",
    "| 4 | 1 | 2 |\n",
    "| 5 | 3 | 4 |\n",
    "| 6 | 1 | 4 |\n",
    "| 7 | 5 | 6 |\n",
    "\n",
    "<!-- TODO add a split here, where on the left we have the table and on the right we have a graphical visualization of the pedigree tree -->\n",
    "\n",
    "\n",
    "We can use the functions defined in this section to form $A$ and $A^{-1}$, and compare the inverse formed to the one formed using NumPy's standard Numerical Linear Algebra tools.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[1.    0.    0.5   0.5   0.5   0.75  0.625]\n",
      " [0.    1.    0.    0.5   0.25  0.25  0.25 ]\n",
      " [0.5   0.    1.    0.25  0.625 0.375 0.5  ]\n",
      " [0.5   0.5   0.25  1.    0.625 0.75  0.688]\n",
      " [0.5   0.25  0.625 0.625 1.125 0.562 0.844]\n",
      " [0.75  0.25  0.375 0.75  0.562 1.25  0.906]\n",
      " [0.625 0.25  0.5   0.688 0.844 0.906 1.281]]\n",
      "Constructed A in 0.00011 seconds\n",
      "\n",
      "A^-1 =\t(from numpy)\n",
      " [[ 2.333  0.5   -0.667 -0.5    0.    -1.     0.   ]\n",
      " [ 0.5    1.5    0.    -1.     0.     0.     0.   ]\n",
      " [-0.667  0.     1.833  0.5   -1.     0.     0.   ]\n",
      " [-0.5   -1.     0.5    3.    -1.    -1.     0.   ]\n",
      " [ 0.     0.    -1.    -1.     2.615  0.615 -1.231]\n",
      " [-1.     0.     0.    -1.     0.615  2.615 -1.231]\n",
      " [ 0.     0.     0.     0.    -1.231 -1.231  2.462]]\n",
      "Numpy inversion in 0.00093 seconds\n",
      "\n",
      "A^-1 =\t(from pedigree)\n",
      " [[ 2.333  0.5   -0.667 -0.5    0.    -1.     0.   ]\n",
      " [ 0.5    1.5    0.    -1.     0.     0.     0.   ]\n",
      " [-0.667  0.     1.833  0.5   -1.     0.     0.   ]\n",
      " [-0.5   -1.     0.5    3.    -1.    -1.     0.   ]\n",
      " [ 0.     0.    -1.    -1.     2.615  0.615 -1.231]\n",
      " [-1.     0.     0.    -1.     0.615  2.615 -1.231]\n",
      " [ 0.     0.     0.     0.    -1.231 -1.231  2.462]]\n",
      "Henderson inversion in 0.00033 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# constructing the pedigree tree\n",
    "ped = readPed(\"example2.ped\")\n",
    "\n",
    "# construction of A\n",
    "tic = perf_counter()\n",
    "A = makeA(ped)\n",
    "toc = perf_counter()\n",
    "printMatrix(A, \"A =\")\n",
    "printTime(\"Constructed A\", tic, toc)\n",
    "\n",
    "# calculating inverse of A\n",
    "tic = perf_counter()\n",
    "numpy_inverse = np.linalg.inv(A)\n",
    "toc = perf_counter()\n",
    "printMatrix(numpy_inverse, \"A^-1 =\\t(from numpy)\")\n",
    "printTime(\"Numpy inversion\", tic, toc)\n",
    "\n",
    "# constructing inverse of A\n",
    "tic = perf_counter()\n",
    "hendo_inverse = make_invA(ped)\n",
    "toc = perf_counter()\n",
    "printMatrix(hendo_inverse, \"A^-1 =\\t(from pedigree)\")\n",
    "printTime(\"Henderson inversion\", tic, toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From external testing we know that $A$ is 91.84\\% dense while $A^{-1}$ is only 65.31\\% dense, meaning the inverse is relatively sparse. We also have that $\\lambda_{\\max}(A) = 4.277$ while $\\lambda_{\\min}(A) = 0.183$, giving that $\\kappa(A) = 23.351$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Toy Problems\n",
    "\n",
    "Now we have worked out how to read in the relevant data, where this arises in optimization problems. In the context of genetic selection, we want to maximize selection of genetic merit (a measure of desirable traits) while minimizing risks due to inbreeding. This is formed mathematically as\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu\\ \\text{ subject to }\\ w_{\\mathcal{S}}^{T}e_{\\mathcal{S}}^{} = \\frac{1}{2},\\ w_{\\mathcal{D}}^{T}e_{\\mathcal{D}}^{} = \\frac{1}{2},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "where $w$ is the vector of proportional contributions, $\\Sigma$ is a matrix encoding risk, $\\mu$ is a vector encoding returns, $l$ encodes lower bounds on contributions, $u$ encodes upper bounds on contributions, $\\mathcal{S}$ is an index set of candidates who are sires, and $\\mathcal{D}$ is an index set of candidates who are dams.\n",
    "\n",
    "In this representation of the problem, $\\lambda$ is a control variable which balances how we trade of between risk and return. Each value of $\\lambda$ will give a different solution on the critical frontier of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Optimization\n",
    "\n",
    "We will start by looking how this problem might be solving using Python's [qpsolvers](https://qpsolvers.github.io/qpsolvers/index.html) library. Since it takes problems of the form\n",
    "$$\n",
    "    \\min_x \\frac{1}{2} x^T A x + q^T x\\ \\text{ subject to }\\ Gx\\leq h,\\ Mx = m,\\ l\\leq x\\leq u,\n",
    "$$\n",
    "we will need to do a very slight rearrangement of the problem to incorporate our two sum-to-half constraints within a single equality constraint. We also do not use the $Gx\\leq h$ constraint in our problem.\n",
    "\n",
    "We observe that the two vector constraints\n",
    "$$\n",
    "    w_{\\mathcal{S}}^{T}e_{\\mathcal{S}}^{} = \\frac{1}{2},\\ w_{\\mathcal{D}}^{T}e_{\\mathcal{D}}^{} = \\frac{1}{2},\n",
    "$$\n",
    "are equivalent to the single matrix constraint\n",
    "$$\n",
    "    Mw := \\begin{bmatrix}\n",
    "        \\mathbb{I}\\lbrace 1\\in\\mathcal{S}\\rbrace & \\mathbb{I}\\lbrace 2\\in\\mathcal{S}\\rbrace & \\cdots & \\mathbb{I}\\lbrace n\\in\\mathcal{S}\\rbrace \\\\\n",
    "        \\mathbb{I}\\lbrace 1\\in\\mathcal{D}\\rbrace & \\mathbb{I}\\lbrace 2\\in\\mathcal{D}\\rbrace & \\cdots & \\mathbb{I}\\lbrace n\\in\\mathcal{D}\\rbrace \\end{bmatrix}w = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\n",
    "$$\n",
    "where $\\mathbb{I}\\lbrace i\\in\\mathcal{I}\\rbrace$ is an indicator function denoting whether index $i$ is in the set of indices $\\mathcal{I}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Standard Example ($n=3$)\n",
    "\n",
    "Lets see how this works in an example. Consider the problem where\n",
    "$$\n",
    "    \\mu = \\begin{bmatrix} 1 \\\\ 5 \\\\ 2, \\end{bmatrix}\\quad\n",
    "    \\Sigma = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 5 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}, \\quad\n",
    "    \\mathcal{S} = \\lbrace 1 \\rbrace, \\quad\n",
    "    \\mathcal{D} = \\lbrace 2, 3 \\rbrace, \\quad\n",
    "    l = {\\bf 0}, \\quad\n",
    "    u = {\\bf 1}.\n",
    "$$\n",
    "We define these variables in Python using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY PROBLEM VARIABLES\n",
    "problem_size = 3\n",
    "expected_breeding_values = np.array([\n",
    "    1.0,\n",
    "    5.0,\n",
    "    2.0\n",
    "])\n",
    "relationship_matrix = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 5, 0],\n",
    "    [0, 0, 3]\n",
    "])\n",
    "sire_indices = [0]\n",
    "dam_indices  = [1,2]\n",
    "lower_bound = np.full((problem_size, 1), 0.0)\n",
    "upper_bound = np.full((problem_size, 1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the additional variables which need setting up so that the problem works in `qpsolvers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZATION SETUP VARIABLES\n",
    "lam = 0.5\n",
    "# define the M so that column i is [1;0] if i is a sire and [0;1] otherwise \n",
    "M = np.zeros((2, problem_size))\n",
    "M[0, sire_indices] = 1\n",
    "M[1, dam_indices] = 1\n",
    "# define the right hand side of the constraint Mx = m\n",
    "m = np.array([[0.5], [0.5]])\n",
    "# set up the vector for the linear objective\n",
    "linear_obj = -lam*expected_breeding_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we solve the problem using the modules' `solve_qp` function. This utilises Gurobi via an API, a fact which will be important once we start to consider larger problem sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-02-26\n",
      "QP solution: w = [0.5   0.375 0.125]\n"
     ]
    }
   ],
   "source": [
    "# SOLVE THE PROBLEM\n",
    "w_standard = solve_qp(\n",
    "    P = relationship_matrix,\n",
    "    q = linear_obj,\n",
    "    G = None,\n",
    "    h = None,\n",
    "    A = M,\n",
    "    b = m,\n",
    "    lb = lower_bound,\n",
    "    ub = upper_bound,\n",
    "    solver = \"gurobi\"\n",
    ")\n",
    "print(f\"QP solution: w = {w_standard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Optimization\n",
    "\n",
    "For robust optimization we adjust the objective function to model the inherent uncertainty in the problem. We may either do this with a quadratic uncertainty set, in which case our objective has an additional square-root term as in\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa\\sqrt{w^{T}\\Omega w}\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "or with a box uncertainty set, in which case our objective has an additional absolute value term as in\n",
    " We may either do this with a quadratic uncertainty set, in which case our objective has an additional square-root term as in\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa\\|\\Omega^{\\frac{1}{2}} w\\|\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "where in both cases $\\kappa\\in\\mathbb{R}$ and $\\Omega\\in\\mathbb{R}^{n\\times n}$ are our robust optimization parameters. This is obviously no longer a quadratic problem, so `qpsolvers` is no longer a viable tool. We will instead now need to work with the Gurobi API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 22 rows, 3 columns and 24 nonzeros\n",
      "Model fingerprint: 0xd96d3c43\n",
      "Model has 3 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 21 rows and 1 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1 rows, 2 columns, 2 nonzeros\n",
      "Presolved model has 2 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 0.000e+00\n",
      " Factor NZ  : 1.000e+00\n",
      " Factor Ops : 1.000e+00 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   5.30849490e+05 -5.31975390e+05  1.50e+03 0.00e+00  3.13e+05     0s\n",
      "   1   7.57990696e+02 -1.61071935e+03  3.58e+01 1.71e-13  7.91e+03     0s\n",
      "   2  -7.64387653e-01 -8.13186089e+02  3.58e-05 1.23e-14  2.03e+02     0s\n",
      "   3  -7.64406933e-01 -2.00154147e+00  1.88e-08 6.43e-14  3.09e-01     0s\n",
      "   4  -7.99897456e-01 -9.97000994e-01  1.46e-09 4.86e-15  4.93e-02     0s\n",
      "   5  -8.12408202e-01 -8.31800574e-01  1.33e-15 2.78e-17  4.85e-03     0s\n",
      "   6  -8.12499997e-01 -8.12540276e-01  0.00e+00 0.00e+00  1.01e-05     0s\n",
      "   7  -8.12500000e-01 -8.12500040e-01  0.00e+00 2.78e-17  1.01e-08     0s\n",
      "   8  -8.12500000e-01 -8.12500000e-01  2.22e-16 5.55e-17  1.01e-11     0s\n",
      "\n",
      "Barrier solved model in 8 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective -8.12500000e-01\n",
      "\n",
      "[0.5   0.375 0.125]\n",
      "Obj: -0.8125\n"
     ]
    }
   ],
   "source": [
    "# randomly set until received from Gregor \n",
    "omega = np.diagflat(np.random.rand(problem_size, 1))\n",
    "kappa = float(np.random.rand(1))\n",
    "\n",
    "# a temp(?) workaround to get the square root with SciPy rather than Numpy.\n",
    "from scipy.linalg import sqrtm\n",
    "root_omega = sqrtm(omega)\n",
    "\n",
    "try:\n",
    "    # create a new model for robust genetic selection\n",
    "    model = gp.Model(\"robustGS\")\n",
    "\n",
    "    # define variable of interest as a continuous \n",
    "    w = model.addMVar(shape=problem_size, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "\n",
    "    # set the objective function\n",
    "    model.setObjective(\n",
    "        # STANDARD OPTIMIZATION OBJECTIVE\n",
    "        0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values,  # standard optimization\n",
    "\n",
    "        # ROBUST OPTIMIZATION OBJECTIVE WITH QUADRATIC UNCERTAINTY\n",
    "        # cannot use np.power, get:\n",
    "        #     TypeError: unsupported operand type(s) for ** or pow(): 'MQuadExpr' and 'float'\n",
    "        # 0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values - kappa*np.power(np.inner(w, omega@w), 0.5),  # inner product representation\n",
    "        # \n",
    "        # cannot use scipy.linalg.sqrtm and np.nla.norm(ord=2), get:\n",
    "        #     ValueError: Improper number of dimensions to norm.\n",
    "        # 0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values - kappa*nla.norm(root_omega@w, ord=2),  # norm representation\n",
    "\n",
    "        # ROBUST OPTIMIZATION OBJECTIVE WITH BOX UNCERTAINTY\n",
    "        # cannot use np.avs, get:\n",
    "        #     TypeError: bad operand type for abs(): 'MQuadExpr'\n",
    "        # 0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values - kappa*np.abs(np.inner(w, omega@w)),  # robust with box uncertainty\n",
    "    GRB.MINIMIZE)\n",
    "\n",
    "    # add sub-to-half constraints\n",
    "    model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "    # add weight-bound constraints\n",
    "    model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "    model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "    # solve the problem with Gurobi\n",
    "    model.optimize()\n",
    "    print(w.X)\n",
    "    print(f\"Obj: {model.ObjVal:g}\")\n",
    "\n",
    "except gp.GurobiError as e:\n",
    "    print(f\"Error code {e.errno}: {e}\")\n",
    "\n",
    "except AttributeError:\n",
    "    # NOTE coding errors sometimes accidentally caught by this \n",
    "    print(\"Encountered an attribute error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 23 rows, 4 columns and 25 nonzeros\n",
      "Model fingerprint: 0xe8d7361e\n",
      "Model has 3 quadratic objective terms\n",
      "Model has 3 quadratic constraints\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  QMatrix range    [4e-01, 1e+00]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 22 rows and 1 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 9 rows, 8 columns, 14 nonzeros\n",
      "Presolved model has 3 second-order cone constraints\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.200e+01\n",
      " Factor NZ  : 4.500e+01\n",
      " Factor Ops : 2.850e+02 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0  -9.02965386e-01 -9.02965386e-01  1.51e+00 7.38e-01  6.76e-01     0s\n",
      "   1  -9.33513427e-01 -1.53929722e+00  1.29e-01 8.12e-07  8.98e-02     0s\n",
      "   2  -8.59473155e-01 -1.00199951e+00  1.42e-07 1.99e-08  1.19e-02     0s\n",
      "   3  -8.66933672e-01 -8.68757572e-01  7.54e-10 1.48e-10  1.52e-04     0s\n",
      "   4  -8.67494911e-01 -8.67498866e-01  9.07e-13 1.31e-13  3.30e-07     0s\n",
      "   5  -8.67495578e-01 -8.67495669e-01  1.93e-10 2.16e-13  7.63e-09     0s\n",
      "\n",
      "Barrier solved model in 5 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective -8.67495578e-01\n",
      "\n",
      "\n",
      "    Variable            X \n",
      "-------------------------\n",
      "        w[0]          0.5 \n",
      "        w[1]     0.328648 \n",
      "        w[2]     0.171352 \n",
      "           z     0.133483 \n",
      "Obj: -0.867496\n"
     ]
    }
   ],
   "source": [
    "# randomly set until received from Gregor\n",
    "omega = np.diagflat(np.random.rand(problem_size, 1))\n",
    "kappa = float(np.random.rand(1))\n",
    "\n",
    "try:\n",
    "    # create a new model for robust genetic selection\n",
    "    model = gp.Model(\"robustGS\")\n",
    "\n",
    "    # define variables of interest as a continuous\n",
    "    w = model.addMVar(shape=problem_size, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "    z = model.addVar(name=\"z\")\n",
    "\n",
    "    # setup the robust objective function\n",
    "    model.setObjective(\n",
    "        0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values -kappa*z,\n",
    "    GRB.MINIMIZE)\n",
    "\n",
    "    # add quadratic uncertainty constraint\n",
    "    model.addConstr(z**2 <= np.inner(w, omega@w), name=\"uncertainty\")\n",
    "    model.addConstr(z >= 0, name=\"z positive\")\n",
    "    # add sub-to-half constraints\n",
    "    model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "    # add weight-bound constraints\n",
    "    model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "    model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "    # solve the problem with Gurobi\n",
    "    model.optimize()\n",
    "    model.printAttr('X')\n",
    "    print(f\"Obj: {model.ObjVal:g}\")\n",
    "\n",
    "except gp.GurobiError as e:\n",
    "    print(f\"Error code {e.errno}: {e}\")\n",
    "\n",
    "except AttributeError:\n",
    "    # NOTE coding errors sometimes accidentally caught by this \n",
    "    print(\"Encountered an attribute error\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
