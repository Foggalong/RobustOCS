{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Optimization for Genetic Selection\n",
    "\n",
    "This is a working notebook, looking at how the quadratic optimization problem (QP) which arises in the context of robust genetic selection can be solved with Python (tested with 3.10 specifically). There are some standard packages which this depends on, imported below.\n",
    "\n",
    "<!-- TODO this needs updating to reflect the current purpose of this file -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # defines matrix structures\n",
    "from qpsolvers import solve_qp      # used for quadratic optimization\n",
    "from time import perf_counter       # fine grained timing \n",
    "import gurobipy as gp               # Gurobi optimization interface (1)\n",
    "from gurobipy import GRB            # Gurobi optimization interface (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions and output settings used in this notebook are defined in the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTime(task, tic, toc):\n",
    "    \"\"\"Quick function for nicely printing a time to 5 s.f.\"\"\"\n",
    "    print(f\"{task} in {toc - tic:0.5f} seconds\\n\")\n",
    "\n",
    "\n",
    "def printMatrix(matrix, description=\"ans =\", precision=3):\n",
    "    \"\"\"Quick function for nicely printing a matrix\"\"\"\n",
    "    print(f\"{description}\\n\", np.round(matrix, precision))\n",
    "\n",
    "\n",
    "# want to round rather than truncate when printing\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# only show numpy output to five decimal places\n",
    "np.set_printoptions(formatter={'float_kind':\"{:.5f}\".format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Problem\n",
    "\n",
    "In the context of genetic selection, we want to maximize selection of genetic merit (a measure of desirable traits) while minimizing risks due to inbreeding. This can be formed mathematically as\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu\\ \\text{ subject to }\\ w_{\\mathcal{S}}^{T}e_{\\mathcal{S}}^{} = \\frac{1}{2},\\ w_{\\mathcal{D}}^{T}e_{\\mathcal{D}}^{} = \\frac{1}{2},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "where $w$ is the vector of proportional contributions, $\\Sigma$ is a matrix encoding risk, $\\mu$ is a vector encoding returns, $l$ encodes lower bounds on contributions, $u$ encodes upper bounds on contributions, $\\mathcal{S}$ is an index set of candidates who are sires, and $\\mathcal{D}$ is an index set of candidates who are dams.\n",
    "\n",
    "In this representation of the problem, $\\lambda$ is a control variable which balances how we trade of between risk and return. Each value of $\\lambda$ will give a different solution on the critical frontier of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Formulation\n",
    "\n",
    "Since it is beneficial to work with problems in a standard form,\n",
    "$$\n",
    "    \\min_x \\frac{1}{2} x^T A x + q^T x\\ \\text{ subject to }\\ Gx\\leq h,\\ Mx = m,\\ l\\leq x\\leq u,\n",
    "$$\n",
    "we will need to do a very slight rearrangement of the problem to incorporate our two sum-to-half constraints within a single equality constraint. We also do not use the $Gx\\leq h$ constraint in our problem.\n",
    "\n",
    "We observe that the two vector constraints\n",
    "$$\n",
    "    w_{\\mathcal{S}}^{T}e_{\\mathcal{S}}^{} = \\frac{1}{2},\\ w_{\\mathcal{D}}^{T}e_{\\mathcal{D}}^{} = \\frac{1}{2},\n",
    "$$\n",
    "are equivalent to the single matrix constraint\n",
    "$$\n",
    "    Mw := \\begin{bmatrix}\n",
    "        \\mathbb{I}\\lbrace 1\\in\\mathcal{S}\\rbrace & \\mathbb{I}\\lbrace 2\\in\\mathcal{S}\\rbrace & \\cdots & \\mathbb{I}\\lbrace n\\in\\mathcal{S}\\rbrace \\\\\n",
    "        \\mathbb{I}\\lbrace 1\\in\\mathcal{D}\\rbrace & \\mathbb{I}\\lbrace 2\\in\\mathcal{D}\\rbrace & \\cdots & \\mathbb{I}\\lbrace n\\in\\mathcal{D}\\rbrace \\end{bmatrix}w = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\n",
    "$$\n",
    "where $\\mathbb{I}\\lbrace i\\in\\mathcal{I}\\rbrace$ is an indicator function denoting whether index $i$ is in the set of indices $\\mathcal{I}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example ($n = 3$)\n",
    "\n",
    "Lets see how this works in an example. We will start by looking how this problem might be solving using Python's [qpsolvers](https://qpsolvers.github.io/qpsolvers/index.html) library. Consider the problem where\n",
    "$$\n",
    "    \\mu = \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix},\\quad\n",
    "    \\Sigma = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 5 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}, \\quad\n",
    "    \\mathcal{S} = \\lbrace 1 \\rbrace, \\quad\n",
    "    \\mathcal{D} = \\lbrace 2, 3 \\rbrace, \\quad\n",
    "    l = {\\bf 0}, \\quad\n",
    "    u = {\\bf 1}.\n",
    "$$\n",
    "We define these variables in Python using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY PROBLEM VARIABLES\n",
    "problem_size = 3\n",
    "expected_breeding_values = np.array([\n",
    "    1.0,\n",
    "    5.0,\n",
    "    2.0\n",
    "])\n",
    "relationship_matrix = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 5, 0],\n",
    "    [0, 0, 3]\n",
    "])\n",
    "sire_indices = [0]\n",
    "dam_indices  = [1,2]\n",
    "lower_bound = np.full((problem_size, 1), 0.0)\n",
    "upper_bound = np.full((problem_size, 1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the additional variables which need setting up so that the problem works in `qpsolvers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZATION SETUP VARIABLES\n",
    "lam = 0.5\n",
    "# define the M so that column i is [1;0] if i is a sire and [0;1] otherwise \n",
    "M = np.zeros((2, problem_size))\n",
    "M[0, sire_indices] = 1\n",
    "M[1, dam_indices] = 1\n",
    "# define the right hand side of the constraint Mx = m\n",
    "m = np.array([[0.5], [0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we solve the problem using the modules' `solve_qp` function. This utilises Gurobi via an API, a fact which will be important once we start to consider larger problem sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-02-26\n",
      "QP solution: w = [0.50000 0.37500 0.12500]\n"
     ]
    }
   ],
   "source": [
    "# SOLVE THE PROBLEM\n",
    "def solveGS(lam):\n",
    "    return solve_qp(\n",
    "        P = relationship_matrix,\n",
    "        q = -lam*expected_breeding_values,\n",
    "        G = None,\n",
    "        h = None,\n",
    "        A = M,\n",
    "        b = m,\n",
    "        lb = lower_bound,\n",
    "        ub = upper_bound,\n",
    "        solver = \"gurobi\"\n",
    "    )\n",
    "\n",
    "print(f\"QP solution: w = {solveGS(lam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, we have code which is telling us that our optimal contributions for $\\lambda = 0.5$ are $w_1 = 0.5$, $w_2 = 0.375$, and $w_3 = 0.125$. We could vary our $\\lambda$ value too and find other points on the frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0: w = [0.50000 0.18750 0.31250]\n",
      "lambda = 0.2: w = [0.50000 0.26250 0.23750]\n",
      "lambda = 0.4: w = [0.50000 0.33750 0.16250]\n",
      "lambda = 0.6: w = [0.50000 0.41250 0.08750]\n",
      "lambda = 0.8: w = [0.50000 0.48750 0.01250]\n",
      "lambda = 1.0: w = [0.50000 0.50000 0.00000]\n"
     ]
    }
   ],
   "source": [
    "print(f\"lambda = 0.0: w = {solveGS(0.0)}\")\n",
    "print(f\"lambda = 0.2: w = {solveGS(0.2)}\")\n",
    "print(f\"lambda = 0.4: w = {solveGS(0.4)}\")\n",
    "print(f\"lambda = 0.6: w = {solveGS(0.6)}\")\n",
    "print(f\"lambda = 0.8: w = {solveGS(0.8)}\")\n",
    "print(f\"lambda = 1.0: w = {solveGS(1.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Optimization\n",
    "\n",
    "A wrinkle to this is that we don't typically our problem variables with certainty. There _are_ ways to define $\\Sigma$ based on relationships within the cohort (which are known and discussed more later) but $\\mu$ is an estimated variable. In particular we say $\\mu$ has a univariate normal distribution, $\\mu\\sim N(\\bar{\\mu}, \\Omega)$. This means we must turn to optimization tools which can address this uncertainty.ยน\n",
    "\n",
    "Robust optimization is one such tool in which we adjust the objective function to model the inherent uncertainty in the problem. We may either do this with a quadratic uncertainty set, in which case our objective has an additional square-root term as in\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa\\sqrt{w^{T}\\Omega w}\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "or with a box uncertainty set, in which case our objective has an additional absolute value term as in\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa\\|\\Omega^{\\frac{1}{2}} w\\|\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "where $\\kappa\\in\\mathbb{R}$ is our robust optimization parameters. For practical reasons relating to continuity and differentiability, the quadratic uncertainty set is far more favourable to work with.\n",
    "\n",
    "This is obviously no longer a quadratic problem, so `qpsolvers` is no longer a viable tool. We will instead now need to work with the Gurobi API directly.\n",
    "\n",
    "<!-- TODO this cell skips over the detail about how to go from the bilevel robust problem to the single level robust problem theory wise, it would be worth delving into that in more detail. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gurobi\n",
    "\n",
    "To illustrate how the setup changes when uncertainty is added, we will first look at how Gurobi handles the standard problem. The following code returns the same solution as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 22 rows, 3 columns and 24 nonzeros\n",
      "Model fingerprint: 0xd96d3c43\n",
      "Model has 3 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [5e-01, 2e+00]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 21 rows and 1 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 1 rows, 2 columns, 2 nonzeros\n",
      "Presolved model has 2 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 0.000e+00\n",
      " Factor NZ  : 1.000e+00\n",
      " Factor Ops : 1.000e+00 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   5.30849490e+05 -5.31975390e+05  1.50e+03 0.00e+00  3.13e+05     0s\n",
      "   1   7.57990696e+02 -1.61071935e+03  3.58e+01 1.71e-13  7.91e+03     0s\n",
      "   2  -7.64387653e-01 -8.13186089e+02  3.58e-05 1.23e-14  2.03e+02     0s\n",
      "   3  -7.64406933e-01 -2.00154147e+00  1.88e-08 6.43e-14  3.09e-01     0s\n",
      "   4  -7.99897456e-01 -9.97000994e-01  1.46e-09 4.86e-15  4.93e-02     0s\n",
      "   5  -8.12408202e-01 -8.31800574e-01  1.33e-15 2.78e-17  4.85e-03     0s\n",
      "   6  -8.12499997e-01 -8.12540276e-01  0.00e+00 0.00e+00  1.01e-05     0s\n",
      "   7  -8.12500000e-01 -8.12500040e-01  0.00e+00 2.78e-17  1.01e-08     0s\n",
      "   8  -8.12500000e-01 -8.12500000e-01  2.22e-16 5.55e-17  1.01e-11     0s\n",
      "\n",
      "Barrier solved model in 8 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective -8.12500000e-01\n",
      "\n",
      "w = [0.50000 0.37500 0.12500]\n"
     ]
    }
   ],
   "source": [
    "# create a model for standard genetic selection\n",
    "model = gp.Model(\"standardGS\")\n",
    "\n",
    "# define variable of interest as a continuous \n",
    "w = model.addMVar(shape=problem_size, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "\n",
    "# set the objective function\n",
    "model.setObjective(\n",
    "    0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "# add sub-to-half constraints\n",
    "model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "# add weight-bound constraints\n",
    "model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "# solve the problem with Gurobi\n",
    "model.optimize()\n",
    "print(f\"w = {w.X}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately Gurobi cannot handle our problem with its objective function in the form\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa\\sqrt{w^{T}\\Omega w}\\ \\text{ subject to }\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u,\n",
    "$$\n",
    "so some further adjustments are needed first. If we define a real auxillary variable $z\\geq0$ such that $z\\leq\\sqrt{w^{T}\\Omega w}$, then our problem becomes\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa z\\ \\text{ s.t. }\\ z\\leq\\sqrt{w^{T}\\Omega w},\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$\n",
    "<!-- TODO: better explain the idea of $z$ pushing up so that this switch doesn't have any practical difference -->\n",
    "However, Gurobi _still_ can't handle this due to the presence of the square root, so we further make use of both $z$ and $\\sqrt{w^{T}\\Omega w}$ being positive to note that $z\\leq\\sqrt{w^{T}\\Omega w}$ can be squared on both sides:\n",
    "$$\n",
    "    \\min_w \\frac{1}{2}w^{T}\\Sigma w - \\lambda w^{T}\\mu - \\kappa z\\ \\text{ s.t. }\\ z^2\\leq w^{T}\\Omega w,\\ Mw = \\begin{bmatrix} 0.5 \\\\ 0.5\\end{bmatrix},\\ l\\leq w\\leq u.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define\n",
    "$$\n",
    "    \\bar{\\mu} = \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix},\\quad\n",
    "        \\Omega = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & \\frac{1}{8} \\end{bmatrix}, \\kappa = 0.5\n",
    "$$\n",
    "and our other problem variables as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 4, 0],\n",
    "    [0, 0, 1/8]\n",
    "])\n",
    "\n",
    "kappa = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then formulate this in Python as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 23 rows, 4 columns and 25 nonzeros\n",
      "Model fingerprint: 0xb2b6242a\n",
      "Model has 3 quadratic objective terms\n",
      "Model has 3 quadratic constraints\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  QMatrix range    [1e-01, 4e+00]\n",
      "  Objective range  [5e-01, 2e+03]\n",
      "  QObjective range [1e+00, 5e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e-01, 1e+00]\n",
      "Presolve removed 22 rows and 1 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 9 rows, 8 columns, 14 nonzeros\n",
      "Presolved model has 3 second-order cone constraints\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 2.200e+01\n",
      " Factor NZ  : 4.500e+01\n",
      " Factor Ops : 2.850e+02 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0  -2.00805657e+02 -2.00805657e+02  1.53e+00 9.37e+02  9.39e+02     0s\n",
      "   1  -3.81137055e+02 -1.14914099e+03  1.90e-01 8.62e+01  1.55e+02     0s\n",
      "   2  -1.77585929e+02 -3.93703673e+02  2.10e-07 4.31e+00  1.89e+01     0s\n",
      "   3  -2.38444850e+02 -2.52225979e+02  1.79e-08 4.72e-02  1.16e+00     0s\n",
      "   4  -2.40612654e+02 -2.40843926e+02  4.23e-10 6.34e-05  1.93e-02     0s\n",
      "   5  -2.40806125e+02 -2.40807190e+02  5.49e-12 6.95e-11  8.87e-05     0s\n",
      "   6  -2.40806532e+02 -2.40806534e+02  1.22e-11 1.35e-09  1.75e-07     0s\n",
      "\n",
      "Barrier solved model in 6 iterations and 0.03 seconds (0.00 work units)\n",
      "Optimal objective -2.40806532e+02\n",
      "\n",
      "w = [0.50000 0.07511 0.42489],\n",
      "z = 0.15022110444836703.\n"
     ]
    }
   ],
   "source": [
    "# create a new model for robust genetic selection\n",
    "model = gp.Model(\"robustGS\")\n",
    "\n",
    "# define variables of interest as a continuous\n",
    "w = model.addMVar(shape=problem_size, vtype=GRB.CONTINUOUS, name=\"w\")\n",
    "z = model.addVar(name=\"z\")\n",
    "\n",
    "# setup the robust objective function\n",
    "model.setObjective(\n",
    "    0.5*w@(relationship_matrix@w) - lam*w.transpose()@expected_breeding_values - kappa*z,\n",
    "GRB.MINIMIZE)\n",
    "\n",
    "# add quadratic uncertainty constraint\n",
    "model.addConstr(z**2 <= np.inner(w, omega@w), name=\"uncertainty\")\n",
    "model.addConstr(z >= 0, name=\"z positive\")\n",
    "# add sub-to-half constraints\n",
    "model.addConstr(M @ w == m, name=\"sum-to-half\")\n",
    "# add weight-bound constraints~\n",
    "model.addConstr(w >= lower_bound, name=\"lower bound\")\n",
    "model.addConstr(w <= upper_bound, name=\"upper bound\")\n",
    "\n",
    "# solve the problem with Gurobi\n",
    "model.optimize()\n",
    "print(f\"w = {w.X},\\nz = {z.X}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this experiment with varying $\\kappa$ to see how how different tolerances for uncertainty impact the robust turning point returned.\n",
    "\n",
    "| $\\kappa$ |        $w$            |   $z$   | $f(w,z)$ |\n",
    "| ---: | ------------------------: | ------: | -------: |\n",
    "|  0.0 | [0.50000 0.37500 0.12500] | 0.02756 | -0.81250 |\n",
    "|  0.5 | [0.50000 0.35282 0.14718] | 0.05204 | -0.83655 |\n",
    "|  1.0 | [0.50000 0.33073 0.16927] | 0.05985 | -0.86451 |\n",
    "|  2.0 | [0.50000 0.28663 0.21337] | 0.07544 | -0.93214 |\n",
    "|  4.0 | [0.50000 0.19816 0.30184] | 0.10671 | -1.11428 |\n",
    "|  8.0 | [0.50000 0.07511 0.42489] | 0.15022 | -1.65453 |\n",
    "| 16.0 | [0.50000 0.07511 0.42489] | 0.15022 | -2.85630 |\n",
    "\n",
    "We can see that in the case $\\kappa = 0$ we return the standard optimization solution, as expected. However, we do have $z\\neq0$ which suggests that a small amount of numerical error has been introduced as a result of asking Gurobi to optimize $z$ as well as $w$.\n",
    "<!-- TODO check that these values are correct, talk about subbing into the KKT conditions -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes\n",
    "\n",
    "1. In reality, $\\Omega$ is also an estimated variable but we can ignore this for now to avoid going down a rabbit hole of uncertainties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
